{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4faxUGzhpEYp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Programming your first Neuronal Network"
      ],
      "metadata": {
        "id": "b9UnHokWPC8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Implementing Forward Propagation"
      ],
      "metadata": {
        "id": "bu3ecl-aQ68D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to this exercise. Here you will implement **forward propagation** for a simple neural network (nn). You will be using [NumPy](https://numpy.org/devdocs/user/). Feel free to consult web references and, of course, use any previously shared materials.\n",
        "\n",
        "You will complete the function `forward_propagation(X,params)` using a nn architecture as follows: Linear -> ReLU -> Linear -> Sigmoid.\n",
        "\n",
        "**Learning objectives:**\n",
        "\n",
        "\n",
        "1.   You will be able to implement the forward propagation step in a simple nn.\n",
        "2.   You will understand how data flows in simple nns using NumPy."
      ],
      "metadata": {
        "id": "XW7oCfBRRiPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FKrcEIuHO9rT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Simulated data (input features)\n",
        "\n",
        "X = np.array([[0.1, 0.5],\n",
        "              [0.3, 0.9],\n",
        "              [0.7, 0.2]])\n",
        "\n",
        "#Simulated parameters of the network\n",
        "params = {'W1': np.array([[0.2, -0.5, 0.1],\n",
        "                    [0.4, 0.3, -0.2]]),\n",
        "          'b1': np.array([[0.1], [-0.3]]),\n",
        "          'W2': np.array([[0.7, -0.1]]),\n",
        "          'b2': np.array([[0.5]])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What is the shape of each parameter? Why do they have this shape?"
      ],
      "metadata": {
        "id": "b5tEU3jWZYpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can print the parameters' shapes\n",
        "\n",
        "for key, value in params.items():\n",
        "    print(f\"{key}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwXiQ09o0Lu9",
        "outputId": "721f8433-8cd1-4f7f-ffa1-b31ec8ae3521"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1: (2, 3)\n",
            "b1: (2, 1)\n",
            "W2: (1, 2)\n",
            "b2: (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation functions\n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))"
      ],
      "metadata": {
        "id": "SKe2TZOOZXL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What does an activation funcion in a nn?"
      ],
      "metadata": {
        "id": "fJRZjaMIaehs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward propagation\n",
        "# Your task is to bring this neural network to life! Fill in the steps of forward\n",
        "# propagation by completing the function below.\n",
        "\n",
        "def forward_propagation(X, params):\n",
        "  \"\"\"\n",
        "  Performs forward propagation for a simple neural network:\n",
        "  Input X → Z1 = W1·X + b1 → A1 = ReLU(Z1) → Z2 = W2·A1 + b2 → Output A2 = Sigmoid(Z2)\n",
        "\n",
        "  Arguments:\n",
        "  X: input data of size (n,m)\n",
        "  parameters: python dictionary containing W1, b1, W2, b2.\n",
        "\n",
        "  Returns:\n",
        "  A2; the output of the sigmoid function.\n",
        "  \"\"\"\n",
        "  #Your code goes here :\n",
        "\n",
        "  A2 = #complete this line with the final output of the network\n",
        "  return A2\n"
      ],
      "metadata": {
        "id": "c2qg-9d0aYGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What you should expect from the forward propagation function? What type of data? What dos it means?\n"
      ],
      "metadata": {
        "id": "cHG8pBefeP6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** If your values don’t match the expected output, how would you check which step is wrong?"
      ],
      "metadata": {
        "id": "Q7tjcaBV4PyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "\n",
        "Complete the `forward_propagation` above using the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Compute the first linear step: Z1 = W1 ⋅ X + b1\n",
        "2.   Apply ReLU: A1 = ReLU(Z1)\n",
        "3.   Compute the second linear step: Z2 = W1 ⋅ A1 + b2\n",
        "4.   Apply sigmoid: A2 = σ(Z2)\n",
        "\n",
        "Yo can use the provided functions `relu` and `sigmoid`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "smu9XiGKcoxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What happens if we don't use an activation function after Z1? What would happen if you skipped the ReLU and sigmoid steps?"
      ],
      "metadata": {
        "id": "17FGTrtecR01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your Forward Propagation"
      ],
      "metadata": {
        "id": "IuD-0s47f67O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have completed the forward propagation exercise, you can test your implementation running the following cell."
      ],
      "metadata": {
        "id": "LqDsDSszhV8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run this test after every modification to your function.\n",
        "\n",
        "def test_forward_propagation(student_funct):\n",
        "  try:\n",
        "\n",
        "      output = student_funct(X,params)\n",
        "      expected_output = np.array([[0.62901652, 0.61939945]]) #result\n",
        "\n",
        "      if output.shape != expected_output.shape: #Shape unit test\n",
        "          print(f\"Output shape does not match the expected shape. Expected {expected_output.shape}, got {output.shape}\")\n",
        "          return\n",
        "\n",
        "      if np.allclose(output, expected_output, atol= 1e-5): #Values unit test\n",
        "          print(\"Output is correct. Great job.\")\n",
        "      else: print(\"Output values are incorrect. Check your matrix operations and activations. Look at the shapes and the values. A2 values should be between 0 and 1\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "#Run test\n",
        "test_forward_propagation(forward_propagation)\n"
      ],
      "metadata": {
        "id": "XCFC-koYhEwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution: Instuctor only\n",
        "\n"
      ],
      "metadata": {
        "id": "4faxUGzhpEYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, params):\n",
        "    W1 = params[\"W1\"]\n",
        "    b1 = params[\"b1\"]\n",
        "    W2 = params[\"W2\"]\n",
        "    b2 = params[\"b2\"]\n",
        "\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    return A2\n",
        "\n",
        "\n",
        "A2 = forward_propagation(X, params)\n"
      ],
      "metadata": {
        "id": "uqsPWVvrpLk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}