{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bu3ecl-aQ68D",
        "IuD-0s47f67O",
        "4faxUGzhpEYp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Programming your first Neuronal Network"
      ],
      "metadata": {
        "id": "b9UnHokWPC8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Impelementing Forward Propagation"
      ],
      "metadata": {
        "id": "bu3ecl-aQ68D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to this exercise. Here you will implement **forward propagation** for a simple neural network (nn). You will be using [NumPy](https://numpy.org/devdocs/user/). Feel free to consult web references and, of course, use any previously shared materials.\n",
        "\n",
        "You will complete the function `forward_propagation(X,params)` using a nn architecture as follows: Linear -> ReLU -> Linear -> Sigmoid.\n",
        "\n",
        "**Objective:** This is the first approach to an understanding of how data flows in nn's."
      ],
      "metadata": {
        "id": "XW7oCfBRRiPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FKrcEIuHO9rT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Simulated data (input features)\n",
        "\n",
        "X = np.array([[0.1, 0.5],\n",
        "              [0.3, 0.9],\n",
        "              [0.7, 0.2]])\n",
        "\n",
        "#Simulated parameters of the network\n",
        "params = {'W1': np.array([[0.2, -0.5, 0.1],\n",
        "                    [0.4, 0.3, -0.2]]),\n",
        "          'b1': np.array([[0.1], [-0.3]]),\n",
        "          'W2': np.array([[0.7, -0.1]]),\n",
        "          'b2': np.array([[0.5]])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What is the shape of each parameter? Why do they have this shape?"
      ],
      "metadata": {
        "id": "b5tEU3jWZYpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation functions\n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))"
      ],
      "metadata": {
        "id": "SKe2TZOOZXL0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What does an activation funcion in a nn?"
      ],
      "metadata": {
        "id": "fJRZjaMIaehs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward propagation\n",
        "\n",
        "def forward_propagation(X, params):\n",
        "  \"\"\"\n",
        "  Performs forward propagation for a simple neural network:\n",
        "  Linear -> ReLU -> Linear -> Sigmoid\n",
        "\n",
        "  Arguments:\n",
        "  X: input dara of size (n,m)\n",
        "  parameters: python dictionary containing W1, b1, W2, b2.\n",
        "\n",
        "  Returns:\n",
        "  A2; the output of the sigmoid function.\n",
        "  \"\"\"\n",
        "  #Your code goes here :\n",
        "\n",
        "  A2 = #complete this line\n",
        "  return A2\n"
      ],
      "metadata": {
        "id": "c2qg-9d0aYGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What you should expect from the forwrd propagation function?What type of data? What dos it means?"
      ],
      "metadata": {
        "id": "cHG8pBefeP6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "\n",
        "Complete the `forward_propagation` above using the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Compute the first linear step: Z1 = W1 ⋅ X + b1\n",
        "2.   Apply ReLU: A1 = ReLU(Z1)\n",
        "3.   Compute the second linear step: Z2 = W1 ⋅ A1 + b2\n",
        "4.   Apply sigmoid: A2 = σ(Z2)\n",
        "\n",
        "Yo can use the provided functions `relu` and `sigmoid`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "smu9XiGKcoxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To think:** What happens if we don't use an activation function after Z1?"
      ],
      "metadata": {
        "id": "17FGTrtecR01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your Forward Propagation"
      ],
      "metadata": {
        "id": "IuD-0s47f67O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have completed the forward propagation exercise, you can test your implementation running the following cell."
      ],
      "metadata": {
        "id": "LqDsDSszhV8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_forward_propagation(student_funct):\n",
        "  try:\n",
        "\n",
        "      output = student_funct(X,params)\n",
        "      expected_output = np.array([[0.62901652, 0.61939945]]) #result\n",
        "\n",
        "      if output.shape != expected_output.shape: #Shape unit test\n",
        "          print(\"Output shape does not match the expected shape.\")\n",
        "          return\n",
        "\n",
        "      if np.allclose(output, expected_output, atol= 1e-5): #Values unit test\n",
        "          print(\"Output is correct.\")\n",
        "      else: print(\"Output values are incorrect. Check your matrix operations and activations. Look at the shapes and the values.\")\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "#Run test\n",
        "test_forward_propagation(forward_propagation)\n"
      ],
      "metadata": {
        "id": "XCFC-koYhEwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution: Instuctor only\n",
        "\n"
      ],
      "metadata": {
        "id": "4faxUGzhpEYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, params):\n",
        "    W1 = params[\"W1\"]\n",
        "    b1 = params[\"b1\"]\n",
        "    W2 = params[\"W2\"]\n",
        "    b2 = params[\"b2\"]\n",
        "\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    return A2\n",
        "\n",
        "\n",
        "A2 = forward_propagation(X, params)\n"
      ],
      "metadata": {
        "id": "uqsPWVvrpLk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}